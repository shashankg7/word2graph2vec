{
  "name": "Word2graph2vec",
  "tagline": "Representation learning for words and Labelled Documents by modelling them as graph (part of IRE Project at IIIT Hyderabad)",
  "body": "### Project Information\r\nThis project is done as part of major project in Information Retreival and Extraction course at IIIT Hyderabad for session 2016-17.\r\n\r\nThe course is taught by [Prof. Vasudeva Varma](https://www.iiit.ac.in/~vv/Home.html) and co-taught by [Prof. Manish Gupta](http://research.microsoft.com/en-us/people/gmanish/).\r\n\r\n### Problem Statement.\r\nRecently there has been an increasing attention to use Deep Learning(DL) techniques to analyze social graphs, such as Flickr, Youtube, Twitter and so on. The beauty of such solution is that once DL is applied, several network mining tasks such as node classification, link prediction, node visualization, node recommendation can be solved by conventional machine learning algorithms.\r\n\r\nIn this project, we will build a model that can capture the network information of a node in an efficient and scalable manner. These learned representations will be used to do nodes classification in our project. \r\n\r\nWe will exploit the labelled information in the data to learn a better representation targeted specifically for classification task.\r\n\r\n### Project gist\r\nThis project studies the problem of embedding very large information networks into low-dimensional vector spaces, which is useful in many tasks such as visualization, node classification, and link prediction. Most existing graph em- bedding methods do not scale for real world information networks which usually contain millions of nodes. In this paper, we implemented a network embedding method called the “PTE(predictive text embedding),” which is suitable for arbitrary types of informa- tion networks: undirected, directed, and/or weighted. \r\n\r\nThe method optimizes a carefully designed objective function that preserves both the local and global network structures. An edge-sampling algorithm is proposed that addresses the limitation of the classical stochastic gradient descent and improves both the effectiveness and the efficiency of the inference. We test the method on IMDB movie review dataset. The novelty in PTE is that it exploits the labelled information in the graph to fine-tune the embeddings.\r\n\r\n### Applications\r\n\r\nBetter representation of nodes helps in solving various network mining tasks by conventional machine learning algorithms. It can be used for:\r\n\r\nNode classification\r\nLink prediction\r\nNode visualization\r\nNode recommendation\r\n\r\n### Links to project resources\r\n[Project Repository](https://github.com/shashankg7/word2graph2vec)\r\n\r\n[Project Report](https://www.overleaf.com/read/sqhkzfvjhfkp)\r\n\r\n[Project Description (video)](https://www.youtube.com/watch?v=2h5TBewzTjM&feature=youtu.be)\r\n\r\n[Project Description (slides)](http://www.slideshare.net/nprateek/predictive-text-embedding-using-line)\r\n\r\n### Authors \r\n[Shashank Gupta](https://github.com/shashankg7)\r\n\r\n[Nishant Prateek](https://github.com/nishantprateek)\r\n\r\n[Karan Chandnani](https://github.com/karan21)\r\n\r\n### References\r\n[LINE](http://www.www2015.it/documents/proceedings/proceedings/p1067.pdf)\r\n\r\n[PTE](http://arxiv.org/abs/1508.00200)\r\n\r\n### Support or Contact\r\nFor any query related to project please feel free to contact any of the author of the project. Contact information is :\r\n\r\nShashank Gupta - shashank.gupta@research.iiit.ac.in\r\n\r\nNishant Prateek - nishant.prateek@research.iiit.ac.in\r\n\r\nKaran Chandnani - karanchandnani21@gmail.com",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}